{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8de3356",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f947ea",
   "metadata": {},
   "source": [
    "This is a Zero Shot Classifier for whisper.\n",
    "The goal is to feed environmental or background sounds as classes to the whisper model and retrieve the probabilities of each class.\n",
    "An classes.text file holds the list of classes each in a square bracket.\n",
    "Additionalal classess can be added to the txt file to increase robustness.\n",
    "Although not integrated, whisper was to trained to support zero-shot classification (according the the whisper research paper.\n",
    "A very helpful repo https://github.com/jumon/zac first mentioned using zero shot for whisper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fdca312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from typing import List, Optional\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from whisper.audio import N_FRAMES, N_MELS, log_mel_spectrogram, pad_or_trim\n",
    "from whisper.model import Whisper\n",
    "from whisper.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f8a6f",
   "metadata": {},
   "source": [
    "# Processing the Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16c6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_audio_features(audio_path: Optional[str], model: Whisper) -> torch.Tensor:\n",
    "    if audio_path is None:\n",
    "        segment = torch.zeros((N_MELS, N_FRAMES), dtype=torch.float32).to(model.device)\n",
    "    else:\n",
    "        mel = log_mel_spectrogram(audio_path)\n",
    "        segment = pad_or_trim(mel, N_FRAMES).to(model.device)\n",
    "    return model.embed_audio(segment.unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1e7e9",
   "metadata": {},
   "source": [
    "# Calculating the log probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25871cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def calculate_average_logprobs(\n",
    "    model: Whisper,\n",
    "    audio_features: torch.Tensor,\n",
    "    class_names: List[str],\n",
    "    tokenizer: Tokenizer,\n",
    ") -> torch.Tensor:\n",
    "    initial_tokens = (\n",
    "        torch.tensor(tokenizer.sot_sequence_including_notimestamps).unsqueeze(0).to(model.device)\n",
    "    )\n",
    "    eot_token = torch.tensor([tokenizer.eot]).unsqueeze(0).to(model.device)\n",
    "\n",
    "    average_logprobs = torch.zeros(len(class_names))\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_name_tokens = (\n",
    "            torch.tensor(tokenizer.encode(\" \" + class_name)).unsqueeze(0).to(model.device)\n",
    "        )\n",
    "        input_tokens = torch.cat([initial_tokens, class_name_tokens, eot_token], dim=1)\n",
    "\n",
    "        logits = model.logits(input_tokens, audio_features)  # (1, T, V)\n",
    "        logprobs = F.log_softmax(logits, dim=-1).squeeze(0)  # (T, V)\n",
    "        logprobs = logprobs[len(tokenizer.sot_sequence_including_notimestamps) - 1 : -1]  # (T', V)\n",
    "        logprobs = torch.gather(logprobs, dim=-1, index=class_name_tokens.view(-1, 1))  # (T', 1)\n",
    "        average_logprob = logprobs.mean().item()\n",
    "        average_logprobs[i] = average_logprob\n",
    "\n",
    "    return average_logprobs\n",
    "\n",
    "\n",
    "def calculate_internal_lm_average_logprobs(\n",
    "    model: Whisper,\n",
    "    class_names: List[str],\n",
    "    tokenizer: Tokenizer,\n",
    "    verbose: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    audio_features_from_empty_input = calculate_audio_features(None, model)\n",
    "    average_logprobs = calculate_average_logprobs(\n",
    "        model=model,\n",
    "        audio_features=audio_features_from_empty_input,\n",
    "        class_names=class_names,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    if verbose:\n",
    "        print(\"Internal LM average log probabilities for each class:\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            print(f\"  {class_name}: {average_logprobs[i]:.3f}\")\n",
    "    return average_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "678097d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import gradio as gr\n",
    "import whisper\n",
    "from whisper.tokenizer import get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e196b",
   "metadata": {},
   "source": [
    "# Zero Shot Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3bf56e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cache = {}\n",
    "\n",
    "\n",
    "def zero_shot_classify(audio_path: str, class_names: str, model_name: str) -> Dict[str, float]:\n",
    "    class_names = class_names.split(\",\")\n",
    "    tokenizer = get_tokenizer(multilingual=\".en\" not in model_name)\n",
    "\n",
    "    if model_name not in model_cache:\n",
    "        model = whisper.load_model(model_name)\n",
    "        model_cache[model_name] = model\n",
    "    else:\n",
    "        model = model_cache[model_name]\n",
    "\n",
    "    internal_lm_average_logprobs = calculate_internal_lm_average_logprobs(\n",
    "        model=model,\n",
    "        class_names=class_names,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    audio_features = calculate_audio_features(audio_path, model)\n",
    "    average_logprobs = calculate_average_logprobs(\n",
    "        model=model,\n",
    "        audio_features=audio_features,\n",
    "        class_names=class_names,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    average_logprobs -= internal_lm_average_logprobs\n",
    "    scores = average_logprobs.softmax(-1).tolist()\n",
    "    return {class_name: score for class_name, score in zip(class_names, scores)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12e8e5e",
   "metadata": {},
   "source": [
    "# Processing the Output in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db599ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary modules\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a52a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract mp3 from any video\n",
    "def video2mp3(video_file, output_ext=\"mp3\"):\n",
    "    filename, ext = os.path.splitext(video_file)\n",
    "    subprocess.call([\"ffmpeg\", \"-y\", \"-i\", video_file, f\"{filename}.{output_ext}\"], \n",
    "                    stdout=subprocess.DEVNULL,\n",
    "                    stderr=subprocess.STDOUT)\n",
    "    return f\"{filename}.{output_ext}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af18b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video file\n",
    "input_video = \"sahsiyet_trim_1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ade835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the mp3 file\n",
    "audio_file = video2mp3(input_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573cdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the classnames. additional classes can be added to the class_names.txt file\n",
    "def extract_class_name():\n",
    "    with open('class_names.txt') as topo_file:\n",
    "        class_names = \"\"\n",
    "        for line in topo_file:\n",
    "            class_names += line + \",\"\n",
    "    return class_names\n",
    "\n",
    "class_names_ = extract_class_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc8ff3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs for the classifier \n",
    "audio_path = audio_file #an audio of a laughter\n",
    "model_name = \"base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86f7475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_prob = zero_shot_classify(audio_path,class_names_,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ffc213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[Gun shot]': 0.97, '[can_opening]\\n': 0.4, '[glass_breaking]\\n': 0.38, '[thunderstorm]\\n': 0.34, '[toilet_flush]\\n': 0.34, '[door_wood_creaks]\\n': 0.29, '[drinking_sipping]\\n': 0.26, '[helicopter whirring]\\n': 0.25, '[car_horn]\\n': 0.24, '[helicopter]\\n': 0.24, '[door_wood_knock]\\n': 0.24, '[pouring_water]\\n': 0.22, '[crackling_fire]\\n': 0.2, '[fireworks]\\n': 0.19, '[vacuum_cleaner]\\n': 0.19, '[water_drops]\\n': 0.18, '[brushing_teeth]\\n': 0.18, '[hand_saw]\\n': 0.18, '[clapping]\\n': 0.17, '[washing_machine]\\n': 0.17, '[sneezing]\\n': 0.16, '[siren]\\n': 0.16, '[snoring]\\n': 0.16, '[coughing]\\n': 0.16, '[laughing]\\n': 0.15, '[chirping_birds]\\n': 0.15, '[sea_waves]\\n': 0.14, '[clock_alarm]\\n': 0.13, '[engine]\\n': 0.12, '[sheep]\\n': 0.12, '[chainsaw]\\n': 0.12, '[clock_tick]\\n': 0.12, '[clock ticking]\\n': 0.12, '[insects]\\n': 0.11, '[airplane]\\n': 0.11, '[crickets]\\n': 0.11, '[church_bells]\\n': 0.11, '[footsteps]\\n': 0.11, '[dog barking]\\n': 0.11, '[cow]\\n': 0.1, '[keyboard_typing]\\n': 0.1, '[crying_baby]\\n': 0.1, '[mouse_click]\\n': 0.1, '[birds chirping]\\n': 0.1, '[breathing]\\n': 0.09, '[train]\\n': 0.08, '[rooster]\\n': 0.08, '[frog]\\n': 0.07, '[pig]\\n': 0.07, '[crow]\\n': 0.07, '[cat]\\n': 0.05, '[wind]\\n': 0.05, '[rain]\\n': 0.05, '[dog]\\n': 0.05, '[hen]\\n': 0.03, '': 0}\n"
     ]
    }
   ],
   "source": [
    "#Scaling the class probabilities for better visualization\n",
    "for key in classes_prob:\n",
    "    #scaling the class probabilities and rounding to 2 decimal places\n",
    "    classes_prob[key] = round(classes_prob[key]*10, 2)\n",
    "    \n",
    "    #this will remove the empty string generated by the output\n",
    "    if key == '':\n",
    "        classes_prob[key] = 0\n",
    "    #sorting by highest probability\n",
    "    dict(sorted(classes_prob.items(), key=lambda item: item[1]))\n",
    "print(dict(sorted(classes_prob.items(), key=lambda item: item[1], reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55c20dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Gun shot]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select the class with the maximum probability\n",
    "background_noise = max(classes_prob, key= lambda x: classes_prob[x])\n",
    "background_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66181371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the opening and closing square brackets\n",
    "background_noise = background_noise[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8653a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the subtitle file (start and end time will be generated automatically in future update)\n",
    "index = 1\n",
    "start_time = \"00:00:01,310\"  \n",
    "end_time = \"00:00:04,000\"\n",
    "seperator = '-->'\n",
    "time = start_time + \" \" + seperator + \" \"+end_time\n",
    "background_noise = background_noise\n",
    "subtitle = [\"1 \\n\", time+\"\\n\", background_noise+\"\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b14b485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open subtitle file, it will create if it doesnt exist\n",
    "srt_file = open(\"srt_file.srt\", \"w\")\n",
    "#add the subtitles line by line\n",
    "srt_file.writelines(subtitle)\n",
    "srt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "919f59dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "00:00:01,310 --> 00:00:04,000\n",
      "Gun shot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Chnaging the file access mode from write to read so that i can print and see the output\n",
    "srt_file = open(\"srt_file.srt\", \"r+\")\n",
    "print(srt_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f0de0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "#it is used to run external programs even from different languages like c and c++. in our case to run an ffmpeg command line command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5df1e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-i', 'sahsiyet_trim_1.mp4', '-vf', \"subtitles=srt_file.srt:force_style='Fontsize=24,Outline=1'\", '-c:v', 'libx264', '-c:a', 'copy', 'output enlgish.mp4'], returncode=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the subttile to the video\n",
    "command = [\n",
    "    \"ffmpeg\",\n",
    "    \"-i\", input_video, #input video\n",
    "    \"-vf\", \"subtitles=srt_file.srt:force_style='Fontsize=24,Outline=1'\", #add the subtitle file here\n",
    "    \"-c:v\", \"libx264\", #hard subtitle\n",
    "    \"-c:a\", \"copy\",\n",
    "    \"output enlgish.mp4\" #output video\n",
    "]\n",
    "\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23078900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import translate_v2 as translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c25dd4",
   "metadata": {},
   "source": [
    "# Turkish background noise\n",
    "Processing the output in turkish\n",
    "\n",
    "Method used: Translating the English background noise output  to Turkish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd9fe7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2437404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0-rc.1\n"
     ]
    }
   ],
   "source": [
    "print(googletrans.__version__) #currently this is the working version, pip install googletrans==4.0.0rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bae685e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e773c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e391d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated = translator.translate(background_noise, dest='turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "073f6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_noise_turk = translated.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "991f21fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silah atışı\n"
     ]
    }
   ],
   "source": [
    "print(background_noise_turk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "978d201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turkish subtitle (time paragms is indiccated during english subtitle)\n",
    "subtitle2 = [\"1 \\n\", time+\"\\n\", background_noise_turk+\"\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed169f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a937afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a subtitle file in Turkish\n",
    "#Open subtitle file, it will create if it doesnt exist\n",
    "srt_file_turk = open(\"srt_file_turk.srt\", \"w\", encoding=\"utf-8\")\n",
    "#add the subtitles line by line\n",
    "srt_file_turk.writelines(subtitle2)\n",
    "srt_file_turk.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e83925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "00:00:01,310 --> 00:00:04,000\n",
      "Silah atÄ±ÅŸÄ±\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Chnaging the file access mode from write to read so that i can print and see the output\n",
    "srt_file = open(\"srt_file_turk.srt\", \"r+\")\n",
    "print(srt_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "237cc2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"test.mp4\"\n",
    "import subprocess\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d07cd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-i', 'test.mp4', '-vf', \"subtitles=sahiyeset (1).srt:force_style='Fontsize=24,Outline=1'\", '-c:v', 'libx264', '-c:a', 'copy', 'output 5.mp4'], returncode=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the subttile to the video\n",
    "command = [\n",
    "    \"ffmpeg\",\n",
    "    \"-i\", video, #input video\n",
    "    \"-vf\", \"subtitles=sahiyeset (1).srt:force_style='Fontsize=24,Outline=1'\", #add the subtitle file here\n",
    "    \"-c:v\", \"libx264\", #hard subtitle, meaning subtitle cannot be seperated from the video afterwards, soft subtitle means the opposite\n",
    "    \"-c:a\", \"copy\",\n",
    "    \"output 5.mp4\" #output video\n",
    "]\n",
    "\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b9898",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "1. Generating the background noise for Audio Segments \n",
    "2. Automatic timestamps\n",
    "3. Combining it with a background noise with subtitle generator\n",
    "4. Adding more classess to the data\n",
    "5. Generating the log probability for each class independently to improve accuracy\n",
    "6. Re-training to improve speed and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa28695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
